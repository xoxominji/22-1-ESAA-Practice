{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0328_박민지",
      "provenance": [],
      "authorship_tag": "ABX9TyM/1+Ln8NA8LihEe/BDbK+W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xoxominji/22-1-ESAA-Practice/blob/main/0328_%EB%B0%95%EB%AF%BC%EC%A7%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [개념정리]\n",
        "\n",
        "## 핸즈온 Chapter 7. 앙상블 학습과 랜덤 포레스트\n",
        "\n",
        "**앙상블 기법(ensemble method)**: 일련의 예측기(분류/회귀 모델)를 모아 학습하는 알고리즘\n",
        "\n"
      ],
      "metadata": {
        "id": "pbKZrdGeTNyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1 투표 기반 분류기\n",
        "\n",
        "\n",
        "- 약한 학습기(weak learner): 랜덤 추측보다 조금 더 높은 성능을 내는 분류기\n",
        "- 강한 학습기(strong learner): 높은 정확도를 냄\n",
        "\n",
        "- **직접 투표(hard voting)**: 다수결 투표\n",
        "- **간접 투표(soft voting)**: 개별 분류기의 예측을 평균 내어 확률이 가장 높은 클래스로 예측 (```predict_proba()```)\n",
        "\n",
        "\n",
        "```\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "VotingClassifier(voting=\"hard\"/\"soft\")\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "> 앙상블 방법은 예측기가 서로다른 알고리즘일 때, 서로 독립일 때 최고의 성능\n",
        "\n",
        "> 앙상블의 예측 > 결정 트리 하나 예측, 더 작은 분산을 만듦\n",
        "\n",
        "> 편향: 배깅 > 페이스팅 (상관관계 줄여 분산 감소)"
      ],
      "metadata": {
        "id": "8Hs4AZw18Jji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2 배깅과 페이스팅\n",
        "- **배깅(bootstrap aggregating)**: 중복 허용 샘플링\n",
        "\n",
        "- **페이스팅(pasting)**: 중복 미허용 샘플링\n",
        "\n",
        "<수집 함수>\n",
        "- 분류: 통계적 최빈값\n",
        "- 회귀: 평균\n",
        "\n",
        "#### 7.2.1 사이킷런의 배깅과 페이스팅\n",
        "\n",
        "\n",
        "```\n",
        "from sklearn.ensemble import BassigClassifier #분류\n",
        "from sklearn.ensemble import BassigRegressor #회귀\n",
        "\n",
        "BaggingClassifier(bootstrap=False, #페이스팅\n",
        "                  n_jobs=#CPU 코어 수#)\n",
        "\n",
        "```\n",
        "#### 7.2.2 oob 평가\n",
        "\n",
        "- **oob(Out-of-Bag)**: 선택되지 않은 훈련 샘플의 나머지\n",
        "\n",
        "예측기가 학습 중에 oob 샘플을 사용하지 않으므로 이 샘플들을 검증 세트로 사용가능 -> 앙상블 모델 자체는 예측기별 oob 평가의 평균값을 이용하여 평가할 수 있음\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "BaggingClassifier(oob_score=True)\n",
        "모델.oob_score_ #출력\n",
        "모델.oob_decision_function_ #oob샘플에 대한 결정 함수 값\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "esN-rIHfK0PA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.3 랜덤 패치와 랜덤 서브스페이스\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "BaggingClassifier(max_samples=#, bootstrap=True/False) #샘플 샘플링\n",
        "BaggingClassifier(max_features=[], bootstrap_features=[]) #특성 샘플링\n",
        "```\n",
        "\n",
        "**랜덤 패치 기법(random patches method)**: 훈련 특성 & 모두 샘플링\n",
        "\n",
        "랜덤 서브스페이스 방식: \n",
        "- ```bootstrap=False``` 그리고 ```max_samples=1.0```\n",
        "- ```bootstrap_features=True``` 또는 ```max_features < 1.0```\n",
        "\n",
        "> 편향을 늘리는 대신 분산을 낮춤"
      ],
      "metadata": {
        "id": "i3Hh3sxCS6m6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.4 랜덤 포레스트\n",
        "\n",
        ": 배깅/페이스팅을 적용한 결정 트리의 앙상블\n",
        "\n",
        "랜덤포레스트 = 배깅(결정 트리)\n",
        "\n",
        "```\n",
        "BaggingClassifier(\n",
        "  DecisionTreeClassifier(max_features=\"auto\", max_leaf_nodes=16),\n",
        "  n_estimators=500,\n",
        "  max_samples=1.0, \n",
        "  bootstrap=True,\n",
        "  n_jobs=-1)\n",
        "```\n",
        "\n",
        "#### 7.4.1 엑스트라 (랜덤) 트리\n",
        "\n",
        ": 최적의 임곗값을 찾는 대신 후보 특성을 사용해 분할한 다음 최상의 분할 선택\n",
        "\n",
        "> 편향 up, 분산 down\n",
        "\n",
        "> speed up\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "ExtraTreesClassifier(n_estimators=, max_leaf_nodes=, n_jobs, ...)\n",
        "```\n",
        "\n",
        "#### 7.4.2 특성 중요도\n",
        "\n",
        ": 어떤 특성을 사용한 노드가 평균적으로 불순도를 얼마나 감소시키는 확인\n",
        "\n",
        "```rf모델.feature_importances_```"
      ],
      "metadata": {
        "id": "PDJv3fR3Vxxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.5 부스팅\n",
        "\n",
        ": 약한 학습기 여러개 연결해 강한 학습기를 만드는 앙상블 방법, 앞 모델을 보완해나가면서 일련의 예측기 학습\n",
        "\n",
        "#### 7.5.1 에이다부스트\n",
        "\n",
        ": 이전 모델이 제대로 학습하지 못한 샘플들에 대한 **가중치를 조절**하여 새로운 모델을 만들어 가는 방식\n",
        "\n",
        "가중치가 적용된 훈련 세트의 전반적인 정화도에 따라 예측기마다 다른 가중치가 적용됨\n",
        "\n",
        "연속된 학습 기법: 영렬화/분할 불가, 배깅/페이스팅만큼 확장성이 높이 않음\n",
        "\n",
        "```\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "AdaBoostClassifier(\n",
        "  DecisionTreeClassifier(max_depth=1),\n",
        "  algorithm=\"SAMME.R\" #클래스 확률 추정\n",
        ")\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "#### 7.5.2 그레이디언트 부스팅\n",
        ": 전 예측기가 만든 **잔여 오차(residual error)**에 대해 새로운 예측기를 학습\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "from sklearn.ensemble import GradientBoostingRegressor/Classifier\n",
        "GradientBoostingRegressor/Classifier()\n",
        "```\n",
        "<매개변수>\n",
        "\n",
        "- ```max_depth``` : ```n_estimators```\n",
        "- ```min_sample_leaf```\n",
        "-```learning_rate```: 각 트리의 기여 정도, < 0.1 이면 '축소' 규제 방법 (훈련 세트 학습 위해 많은 트리가 필요하지만 예측 성능이 좋아짐)\n",
        "\n",
        "- ```staged_predict(X_val)``` : 최적의 트리 수 찾기\n",
        "- ```warm_start```: 조기 종료\n",
        "- ```subsample```: 훈련에 사용할 훈련 샘플 비율 지정 (편향 up, 분산 down), 0.25 지정시 **확률적 그레이디언트 부스팅(stochastic gradient boosting)**\n"
      ],
      "metadata": {
        "id": "G0fur1lEbIke"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.6 스태킹\n",
        "\n",
        "\"앙상블에 속한 모든 예측기의 예측을 취합하는 간단한 함수를 사용하는 대신 취합하는 모델을 훈련시킬 수 없을까?\"\n",
        "\n",
        "1. 훈련 세트를 두 개의 서브셋으로 나누기\n",
        "2. 첫 번째 서브셋으로 첫번째 레이어의 예측 훈련\n",
        "3. 첫 번째 레이어의 예측기로 두번째 홀드 아웃 세트에 대한 예측\n",
        "4. 각 샘플에 대한 여러 개의 예측값으로 새로운 훈련 세트 생성 (n차원)\n",
        "5. 새 훈련 세트로 **메타 학습기** 훈련"
      ],
      "metadata": {
        "id": "1wX4ffIEsqMo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [필사]"
      ],
      "metadata": {
        "id": "htYWgQmH9kbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# moons 데이터셋 생성\n",
        "from sklearn.datasets import make_moons\n",
        "X, y = make_moons(n_samples=1000, noise=0.15)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "GgN7LLOd_yUa"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S61YXiHoSWNe",
        "outputId": "58804f6a-7e2d-45a5-a5c3-1b9c86ca2a4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
              "                             ('rf', RandomForestClassifier()), ('svc', SVC())])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# 다수결 분류기\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "log_clf = LogisticRegression()\n",
        "rnd_clf = RandomForestClassifier()\n",
        "svm_clf = SVC()\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)], voting='hard')\n",
        "\n",
        "voting_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psUDt1l4-Q_n",
        "outputId": "bb8f39ce-7387-44ef-a066-6d376da911b8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression 0.895\n",
            "RandomForestClassifier 0.98\n",
            "SVC 0.985\n",
            "VotingClassifier 0.985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#배깅\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(), \n",
        "    n_estimators=500,\n",
        "    max_samples=100, \n",
        "    n_jobs=-1)\n",
        "\n",
        "bag_clf.fit(X_train, y_train)\n",
        "y_pred = bag_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "H-t1jx5K-ZqX"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# oob\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(), \n",
        "    n_estimators=500,\n",
        "    bootstrap=True, \n",
        "    oob_score=True)\n",
        "\n",
        "bag_clf.fit(X_train, y_train)\n",
        "bag_clf.oob_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8xdWx3WP6fb",
        "outputId": "09b66be1-f10a-4447-ef91-57025f2ea89b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.985"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwNEBiycSghq",
        "outputId": "638e27fd-8687-48a2-d840-21362d7b5d98"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.98"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bag_clf.oob_decision_function_[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psOWaaC0SlDu",
        "outputId": "d56188f4-623e-47a8-88ce-a306ec05ad8b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.97175141, 0.02824859]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "dyJnydHrrjgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#랜덤 포레스트\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
        "rnd_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rf = rnd_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "rJb0RqGnSpfH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag_clf = BaggingClassifier(\n",
        "      DecisionTreeClassifier(max_features=\"auto\", max_leaf_nodes=16),\n",
        "      n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=-1)"
      ],
      "metadata": {
        "id": "QcyWlmU7YAi_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rf: 특성 중요도\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
        "rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
        "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
        "    print(name, score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHPviGMUYJp6",
        "outputId": "17cda603-a7d2-4096-fa18-6fd7897b7396"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sepal length (cm) 0.10735261943150355\n",
            "sepal width (cm) 0.024315584300831104\n",
            "petal length (cm) 0.4542284430950481\n",
            "petal width (cm) 0.4141033531726171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "U-HQ6G-2ric3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#에이다부스팅\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(max_depth=1), \n",
        "    n_estimators=200,\n",
        "    algorithm=\"SAMME.R\", \n",
        "    learning_rate=0.5)\n",
        "\n",
        "ada_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIXYfXrPYWV-",
        "outputId": "c4c519d8-d19b-434b-e411-e351466b0f00"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
              "                   learning_rate=0.5, n_estimators=200)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#그레이디언트 부스팅\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg1 = DecisionTreeRegressor(max_depth=2)\n",
        "tree_reg1.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS0CusIVrwzG",
        "outputId": "99e58065-6d3d-4083-8bca-3de2f97dec79"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y2 = y - tree_reg1.predict(X)\n",
        "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
        "tree_reg2.fit(X, y2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HI38xuyFr3H2",
        "outputId": "3c0b8728-2584-43e4-a32a-9d5e91b8a889"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y3 = y2 - tree_reg2.predict(X)\n",
        "tree_reg3 = DecisionTreeRegressor(max_depth=2)\n",
        "tree_reg3.fit(X, y3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk6Zdtm8r5SF",
        "outputId": "382c2a5e-d597-4ec5-b299-353885eb796d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X_new = np.array([[0.8]]) # 새로운 샘플\n",
        "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3)) # 모든 예측값 더하기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "ULRXWEVzr7Dr",
        "outputId": "6d35cb82-780c-4c6f-fd74-5b84a7cabf2d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-10e092a5e970>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 새로운 샘플\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtree_reg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_reg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_reg3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 모든 예측값 더하기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-41-10e092a5e970>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 새로운 샘플\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtree_reg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_reg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_reg3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 모든 예측값 더하기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[1;32m    466\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;34m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             if issparse(X) and (\n\u001b[1;32m    435\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             raise ValueError(\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: X has 1 features, but DecisionTreeRegressor is expecting 2 features as input."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0)\n",
        "gbrt.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnmFvu1VsBED",
        "outputId": "12ccdaa2-515c-4b34-80eb-1408e6abc947"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(learning_rate=1.0, max_depth=2, n_estimators=3)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# 이전 학습 내용을 지우고 새로 훈련하기 위해 훈련 세트 섞기. \n",
        "# random_state를 다른 값으로 지정.\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
        "\n",
        "# GBRT 모델 설정 및 훈련\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120)\n",
        "gbrt.fit(X_train, y_train)\n",
        "\n",
        "# staged_predict()에 의해 생성된 반복자를 활용하여\n",
        "# 각 단계별 MSE 수집 후 최소값을 갖는 인덱스 확인\n",
        "errors = [mean_squared_error(y_val, y_pred)\n",
        "          for y_pred in gbrt.staged_predict(X_val)]\n",
        "bst_n_estimators = np.argmin(errors) + 1\n",
        "\n",
        "# 최적의 의사결정나무 수를 이용하여 새로 학습\n",
        "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=bst_n_estimators)\n",
        "gbrt_best.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHSOeK-ZsMDF",
        "outputId": "435a075b-3837-4ef9-e951-050e083118a1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(max_depth=2, n_estimators=120)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# n_estimators 파라미터를 지정하지 않은 채로 모델 설정\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True)\n",
        "\n",
        "# MSE 최솟값 보관용\n",
        "min_val_error = float(\"inf\")\n",
        "\n",
        "# MSE의 변화가 없거나 나빠지는 횟수 측정. 5회까지 기다리기.\n",
        "error_going_up = 0\n",
        "\n",
        "# n_estimators를 1부터 120까지 실험\n",
        "for n_estimators in range(1, 120):\n",
        "    # GBRT의 n_estimators 설정 후 학습\n",
        "    gbrt.n_estimators = n_estimators\n",
        "    gbrt.fit(X_train, y_train)\n",
        "    \n",
        "    # MSE 측정\n",
        "    y_pred = gbrt.predict(X_val)\n",
        "    val_error = mean_squared_error(y_val, y_pred)\n",
        "    \n",
        "    # MSE가 낮아졌을 경우 최솟값 업데이트.\n",
        "    # 아니면 5번 정도 기다렸다가 조기 종료할 것.\n",
        "    if val_error < min_val_error:\n",
        "        min_val_error = val_error\n",
        "        error_going_up = 0\n",
        "    else:\n",
        "        error_going_up += 1\n",
        "        if error_going_up == 5:\n",
        "            break"
      ],
      "metadata": {
        "id": "HJ8B49uasSfH"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost\n",
        "\n",
        "xgb_reg = xgboost.XGBRegressor()\n",
        "xgb_reg.fit(X_train, y_train)\n",
        "y_pred = xgb_reg.predict(X_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiijjQLesZTi",
        "outputId": "76dc1bd5-72d2-4280-d38f-94d91b4ce254"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:43:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_reg.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=2)\n",
        "y_pred = xgb_reg.predict(X_val)\n",
        "val_error = mean_squared_error(y_val, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK_Jutc1sdDv",
        "outputId": "dd042cb6-bd9a-436f-bfb5-a02e289eea0d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:44:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[0]\tvalidation_0-rmse:0.462332\n",
            "Will train until validation_0-rmse hasn't improved in 2 rounds.\n",
            "[1]\tvalidation_0-rmse:0.429475\n",
            "[2]\tvalidation_0-rmse:0.400964\n",
            "[3]\tvalidation_0-rmse:0.376247\n",
            "[4]\tvalidation_0-rmse:0.355539\n",
            "[5]\tvalidation_0-rmse:0.337305\n",
            "[6]\tvalidation_0-rmse:0.322274\n",
            "[7]\tvalidation_0-rmse:0.305324\n",
            "[8]\tvalidation_0-rmse:0.293274\n",
            "[9]\tvalidation_0-rmse:0.279954\n",
            "[10]\tvalidation_0-rmse:0.27075\n",
            "[11]\tvalidation_0-rmse:0.260689\n",
            "[12]\tvalidation_0-rmse:0.252376\n",
            "[13]\tvalidation_0-rmse:0.244821\n",
            "[14]\tvalidation_0-rmse:0.238213\n",
            "[15]\tvalidation_0-rmse:0.232236\n",
            "[16]\tvalidation_0-rmse:0.224774\n",
            "[17]\tvalidation_0-rmse:0.219637\n",
            "[18]\tvalidation_0-rmse:0.213365\n",
            "[19]\tvalidation_0-rmse:0.209135\n",
            "[20]\tvalidation_0-rmse:0.204201\n",
            "[21]\tvalidation_0-rmse:0.200707\n",
            "[22]\tvalidation_0-rmse:0.196584\n",
            "[23]\tvalidation_0-rmse:0.193711\n",
            "[24]\tvalidation_0-rmse:0.190399\n",
            "[25]\tvalidation_0-rmse:0.188029\n",
            "[26]\tvalidation_0-rmse:0.185392\n",
            "[27]\tvalidation_0-rmse:0.183461\n",
            "[28]\tvalidation_0-rmse:0.181183\n",
            "[29]\tvalidation_0-rmse:0.179595\n",
            "[30]\tvalidation_0-rmse:0.17781\n",
            "[31]\tvalidation_0-rmse:0.176223\n",
            "[32]\tvalidation_0-rmse:0.174717\n",
            "[33]\tvalidation_0-rmse:0.173214\n",
            "[34]\tvalidation_0-rmse:0.172171\n",
            "[35]\tvalidation_0-rmse:0.171385\n",
            "[36]\tvalidation_0-rmse:0.170734\n",
            "[37]\tvalidation_0-rmse:0.17013\n",
            "[38]\tvalidation_0-rmse:0.16932\n",
            "[39]\tvalidation_0-rmse:0.168772\n",
            "[40]\tvalidation_0-rmse:0.168176\n",
            "[41]\tvalidation_0-rmse:0.167237\n",
            "[42]\tvalidation_0-rmse:0.166257\n",
            "[43]\tvalidation_0-rmse:0.165441\n",
            "[44]\tvalidation_0-rmse:0.164513\n",
            "[45]\tvalidation_0-rmse:0.162787\n",
            "[46]\tvalidation_0-rmse:0.161972\n",
            "[47]\tvalidation_0-rmse:0.160687\n",
            "[48]\tvalidation_0-rmse:0.159462\n",
            "[49]\tvalidation_0-rmse:0.159287\n",
            "[50]\tvalidation_0-rmse:0.158577\n",
            "[51]\tvalidation_0-rmse:0.157982\n",
            "[52]\tvalidation_0-rmse:0.156339\n",
            "[53]\tvalidation_0-rmse:0.15613\n",
            "[54]\tvalidation_0-rmse:0.154288\n",
            "[55]\tvalidation_0-rmse:0.153366\n",
            "[56]\tvalidation_0-rmse:0.151871\n",
            "[57]\tvalidation_0-rmse:0.150364\n",
            "[58]\tvalidation_0-rmse:0.149722\n",
            "[59]\tvalidation_0-rmse:0.149078\n",
            "[60]\tvalidation_0-rmse:0.148369\n",
            "[61]\tvalidation_0-rmse:0.147272\n",
            "[62]\tvalidation_0-rmse:0.146755\n",
            "[63]\tvalidation_0-rmse:0.145566\n",
            "[64]\tvalidation_0-rmse:0.145251\n",
            "[65]\tvalidation_0-rmse:0.145101\n",
            "[66]\tvalidation_0-rmse:0.144374\n",
            "[67]\tvalidation_0-rmse:0.144253\n",
            "[68]\tvalidation_0-rmse:0.143851\n",
            "[69]\tvalidation_0-rmse:0.142844\n",
            "[70]\tvalidation_0-rmse:0.142361\n",
            "[71]\tvalidation_0-rmse:0.141377\n",
            "[72]\tvalidation_0-rmse:0.140788\n",
            "[73]\tvalidation_0-rmse:0.140404\n",
            "[74]\tvalidation_0-rmse:0.140146\n",
            "[75]\tvalidation_0-rmse:0.139354\n",
            "[76]\tvalidation_0-rmse:0.139119\n",
            "[77]\tvalidation_0-rmse:0.138936\n",
            "[78]\tvalidation_0-rmse:0.138233\n",
            "[79]\tvalidation_0-rmse:0.138276\n",
            "[80]\tvalidation_0-rmse:0.138057\n",
            "[81]\tvalidation_0-rmse:0.137405\n",
            "[82]\tvalidation_0-rmse:0.136759\n",
            "[83]\tvalidation_0-rmse:0.13632\n",
            "[84]\tvalidation_0-rmse:0.135734\n",
            "[85]\tvalidation_0-rmse:0.135493\n",
            "[86]\tvalidation_0-rmse:0.134647\n",
            "[87]\tvalidation_0-rmse:0.134245\n",
            "[88]\tvalidation_0-rmse:0.133747\n",
            "[89]\tvalidation_0-rmse:0.133476\n",
            "[90]\tvalidation_0-rmse:0.133291\n",
            "[91]\tvalidation_0-rmse:0.132905\n",
            "[92]\tvalidation_0-rmse:0.132695\n",
            "[93]\tvalidation_0-rmse:0.132058\n",
            "[94]\tvalidation_0-rmse:0.131811\n",
            "[95]\tvalidation_0-rmse:0.131489\n",
            "[96]\tvalidation_0-rmse:0.131477\n",
            "[97]\tvalidation_0-rmse:0.131307\n",
            "[98]\tvalidation_0-rmse:0.13114\n",
            "[99]\tvalidation_0-rmse:0.130943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "45wsdX2SsnMS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}